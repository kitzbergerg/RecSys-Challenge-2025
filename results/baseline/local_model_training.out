/home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.venv/lib/python3.10/site-packages/lightning_fabric/__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
WARNING:training_pipeline.logger_factory:No Neptune project is specified, loggin offline. To specify Neptune project, add command line argument --neptune-project workspace/project
INFO:validator.utils:client ids loaded
INFO:validator.utils:embeddings loaded
WARNING:validator.embeddings_validator:Validator will not check if the content of client_ids.npy matches with the list of relevant clients. Embeddings may not conform to competition format.
INFO:validator.utils:client ids are valid
INFO:validator.utils:embeddings are valid
INFO:validator.utils:embeddings and client ids have the same length
INFO:validator.validate:Validator checks passed
INFO:training_pipeline.train_runner:Running on churn
INFO:training_pipeline.train_runner:Constructing task specific data structures
INFO:training_pipeline.train_runner:Transforming client ids
INFO:training_pipeline.train_runner:Setting up training logger
INFO:training_pipeline.train_runner:Running training
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('Radeon RX 7900 XTX') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[neptune] [info   ] Neptune initialized. Open in the app: offline/3c0c7ba4-38dd-43c9-9648-d9198ccebb85
[neptune] [warning] /home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.venv/lib/python3.10/site-packages/pytorch_lightning/loggers/neptune.py:396: NeptuneWarning: Info (NVML): NVML Shared Library Not Found. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/help/nvml_error/
INFO:training_pipeline.data_module:Constructing datasets
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
┏━━━┳━━━━━━┳━━━━━━┳━━━━━━━━┓
┃   ┃ Name ┃ Type ┃ Params ┃
┡━━━╇━━━━━━╇━━━━━━╇━━━━━━━━┩
│ 0 │ net  │ Net  │ 51.0 M │
└───┴──────┴──────┴────────┘
Trainable params: 51.0 M
Non-trainable params: 0
Total params: 51.0 M
Total estimated model params size (MB): 204
[neptune] [warning] Warning: string series 'monitoring/e6da0175/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.
/home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at
../aten/src/ATen/Context.cpp:296.)
  return F.linear(input, self.weight, self.bias)
/home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3429) is smaller than the logging interval Trainer(log_every_n_steps=5000). Set a lower value for log_every_n_steps if you
want to see logs for the training epoch.
Epoch 0/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3429/3429 0:00:40 • 0:00:00 87.80it/s v_num: LINE train_loss: 0.690 val_loss: 0.750 val_auroc: 0.464
Epoch 1/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3429/3429 0:00:39 • 0:00:00 87.18it/s v_num: LINE train_loss: 0.682 val_loss: 0.783 val_auroc: 0.492
Epoch 2/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3429/3429 0:00:39 • 0:00:00 88.05it/s v_num: LINE train_loss: 0.683 val_loss: 0.783 val_auroc: 0.492`Trainer.fit` stopped: `max_epochs=3` reached.
Epoch 2/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3429/3429 0:00:39 • 0:00:00 88.05it/s v_num: LINE train_loss: 0.683 val_loss: 0.827 val_auroc: 0.538
[neptune] [info   ] Shutting down background jobs, please wait a moment...
[neptune] [info   ] Done!
INFO:training_pipeline.train_runner:Run on churn completed
INFO:training_pipeline.train_runner:Running on propensity_category
INFO:training_pipeline.train_runner:Constructing task specific data structures
INFO:training_pipeline.train_runner:Transforming client ids
INFO:training_pipeline.train_runner:Setting up training logger
INFO:training_pipeline.train_runner:Running training
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[neptune] [info   ] Neptune initialized. Open in the app: offline/a8d7da2f-66b7-4417-b910-f7e1cf7e92e2
INFO:training_pipeline.data_module:Constructing datasets
/home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.neptune/offline-name/OFFLINE/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
┏━━━┳━━━━━━┳━━━━━━┳━━━━━━━━┓
┃   ┃ Name ┃ Type ┃ Params ┃
┡━━━╇━━━━━━╇━━━━━━╇━━━━━━━━┩
│ 0 │ net  │ Net  │ 51.2 M │
└───┴──────┴──────┴────────┘
Trainable params: 51.2 M
Non-trainable params: 0
Total params: 51.2 M
Total estimated model params size (MB): 204
[neptune] [warning] Warning: string series 'monitoring/e6da0175/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.
/home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)  # noqa: B028
Epoch 0/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6707/6707 0:01:17 • 0:00:00 86.54it/s v_num: LINE train_loss: 0.006 val_loss: 0.002 val_auroc: 0.620 val_diversity: 0.876 val_novelty: 0.945
Epoch 1/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6707/6707 0:01:21 • 0:00:00 81.84it/s v_num: LINE train_loss: 0.006 val_loss: 0.002 val_auroc: 0.625 val_diversity: 0.901 val_novelty: 0.895
Epoch 2/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6707/6707 0:01:17 • 0:00:00 86.92it/s v_num: LINE train_loss: 0.006 val_loss: 0.002 val_auroc: 0.625 val_diversity: 0.901 val_novelty: 0.895`Trainer.fit` stopped: `max_epochs=3` reached.
Epoch 2/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6707/6707 0:01:17 • 0:00:00 86.92it/s v_num: LINE train_loss: 0.006 val_loss: 0.002 val_auroc: 0.631 val_diversity: 0.907 val_novelty: 0.883
[neptune] [info   ] Shutting down background jobs, please wait a moment...
[neptune] [info   ] Done!
INFO:training_pipeline.train_runner:Run on propensity_category completed
INFO:training_pipeline.train_runner:Running on propensity_sku
INFO:training_pipeline.train_runner:Constructing task specific data structures
INFO:training_pipeline.train_runner:Transforming client ids
INFO:training_pipeline.train_runner:Setting up training logger
INFO:training_pipeline.train_runner:Running training
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[neptune] [info   ] Neptune initialized. Open in the app: offline/1f8e3895-966a-46ca-b541-bc95ad1e82d3
INFO:training_pipeline.data_module:Constructing datasets
/home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.neptune/offline-name/OFFLINE/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
┏━━━┳━━━━━━┳━━━━━━┳━━━━━━━━┓
┃   ┃ Name ┃ Type ┃ Params ┃
┡━━━╇━━━━━━╇━━━━━━╇━━━━━━━━┩
│ 0 │ net  │ Net  │ 51.2 M │
└───┴──────┴──────┴────────┘
Trainable params: 51.2 M
Non-trainable params: 0
Total params: 51.2 M
Total estimated model params size (MB): 204
[neptune] [warning] Warning: string series 'monitoring/e6da0175/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.
/home/gabriel/Dev/Uni/TUW-RecSys-group-project/Rec-Sys-Challenge-Github-Repo/.venv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)  # noqa: B028
Epoch 0/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6707/6707 0:01:16 • 0:00:00 87.21it/s v_num: LINE train_loss: 0.000 val_loss: 0.000 val_auroc: 0.548 val_diversity: 0.405 val_novelty: 0.992
Epoch 1/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6707/6707 0:01:18 • 0:00:00 87.40it/s v_num: LINE train_loss: 0.000 val_loss: 0.000 val_auroc: 0.547 val_diversity: 0.712 val_novelty: 0.995
Epoch 2/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6707/6707 0:01:18 • 0:00:00 86.87it/s v_num: LINE train_loss: 0.000 val_loss: 0.000 val_auroc: 0.547 val_diversity: 0.712 val_novelty: 0.995`Trainer.fit` stopped: `max_epochs=3` reached.
Epoch 2/2  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6707/6707 0:01:18 • 0:00:00 86.87it/s v_num: LINE train_loss: 0.000 val_loss: 0.000 val_auroc: 0.565 val_diversity: 0.738 val_novelty: 0.995
[neptune] [info   ] Shutting down background jobs, please wait a moment...
[neptune] [info   ] Done!
INFO:training_pipeline.train_runner:Run on propensity_sku completed
